最近在对一个项目做故障注入测试，测试的场景如下：
```
+-------------------+        +-----------------------+       +--------------------------+
|                   |        |                       |       |                          |
|   Test Client     +------->+    Stateless Frontend +------>+   Stateful Backend       |
|                   |        |                       |       |                          |
+-------------------+        +-----------------------+       +--------------------------+
```
其中一项测试是考察无状态前端在有状态后段服务宕机场景下的表现。使用[Linux sysrq](https://www.kernel.org/doc/html/v4.15/admin-guide/sysrq.html)来模拟宕机。首先对后端服务所在系统开启sysrq：
```bash
$ sudo sh -c "echo 1 > /proc/sys/kernel/sysrq"
```
在测试端持续压力下，重启后端机器：
```bash
$ sudo sh -c "echo b > /proc/sysrq-trigger" 
```
这种方法重启机器，内核不会对操作系统进行unmount，也不回关闭网络链接等。

我们遇到的问题是，后端服务重启之后很长一段时间，前端仍然会以一定的概率报错。前端日志显示是网络超时，但是搜索后端日志，发现请求并没有到达。前端日志还显示了错误的一个共性，就是这些超时请求都发生在同一个线程。于是，我们猜想请求一定是卡在这个线程里了。

于是采用`JProfiler`对该Java进程生成了一个`HPROF` dump文件，并进行分析（也可以采用`jmap`生成dump，用`mat`进行分析）。分析发现，该进程从其对应的连接池里已经没有剩余的到曾经宕机的机器的连接了。同时确认，有5个到宕机机器的请求一直在inflight队列里，等待后端返回payload。因为网络模型是基于线程池的，一旦线程池的连接全部用于inflight请求了，自然新的请求就会被饿死。但问题是为什么这些请求一直收不到网络事件呢，那么是网络异常关闭？

经过查证，原因是这些网络连接在后端宕机后一直处于等待对方回包，而由于后端机器重启，连接也并没有被关闭，所以这些连接一直处于`idle`状态。那么linux对于处于idle状态的连接是如何处理的呢？这取决于下面三个kernel的设置：
```
net.ipv4.tcp_keepalive_time = 7200
net.ipv4.tcp_keepalive_intvl = 75
net.ipv4.tcp_keepalive_probes = 9
```
注意到缺省的`net.ipv4.tcp_keepalive_time`是`7200`秒，也就是两个小时。含义是一个连接空闲达到两个小时的时候，kernel才会发keepalive请求，确认对端是否存活。Keepalive请求以每75秒为间隔，最多发送9次。当对端一直不回应是，则关闭连接。于是，我们又查看了一下客户端请求日志，发现果然在两个小时后，不再有新的错误发生了。

至此，我们已经基本确认这个问题的根源了。最直接的解决方案是采用`setsockopt`对这些连接设置`TCP_KEEPIDLE`、`TCP_KEEPINTVL`、`TCP_KEEPCNT`，分别复写上面三个系统级别的参数。我们采用改变系统配置来解决该问题：
```
net.ipv4.tcp_keepalive_time = 90
net.ipv4.tcp_keepalive_intvl = 10
net.ipv4.tcp_keepalive_probes = 3
```
这样在一个连接空闲90秒之后就开始探测对端是否存活，能够有效的避免因宕机导致的错误。

改完参数之后，我们做了同样的测试，并用`tcpdump`在前端机器上抓包。能够发现在90秒之后，前端机器向后端机器发送keepalive包，并在没有收到回复后，最终关闭了连接。

**参考**：
* [TCP-Keepalive-HOWTO](http://www.tldp.org/HOWTO/html_single/TCP-Keepalive-HOWTO/)